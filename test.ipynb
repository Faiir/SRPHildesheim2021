{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1307])\n",
      "tensor([0.3015])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR100\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import gc \n",
    "from torchvision.datasets import MNIST, FashionMNIST, SVHN, CIFAR10\n",
    "\n",
    "def tmp_func(x):\n",
    "    return x.repeat(3, 1, 1)\n",
    "\n",
    "mnist =MNIST(\n",
    "            root=r\"/dataset/MNIST\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                    [\n",
    "                transforms.ToTensor(),\n",
    "\n",
    "                    ]\n",
    "                ))\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    mnist,\n",
    "    batch_size=10,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nimages = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for batch, _ in loader:\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = torch.unsqueeze(batch, 1)\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    std += batch.std(2).sum(0)\n",
    "\n",
    "# Final step\n",
    "mean /= nimages\n",
    "std /= nimages\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img,_ = next(iter(loader))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1307]) tensor([0.3015])\n"
     ]
    }
   ],
   "source": [
    "print(mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2860])\n",
      "tensor([0.3205])\n"
     ]
    }
   ],
   "source": [
    "FashionM =FashionMNIST(\n",
    "            root=r\"/dataset/FashionMNIST\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                    [\n",
    "                transforms.ToTensor(),\n",
    "                    ]\n",
    "                ))\n",
    "\n",
    "loader = DataLoader(\n",
    "    FashionM,\n",
    "    batch_size=10,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "nimages = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for batch, _ in loader:\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    std += batch.std(2).sum(0)\n",
    "\n",
    "# Final step\n",
    "mean /= nimages\n",
    "std /= nimages\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor([0.5071, 0.4865, 0.4409])\n",
      "tensor([0.2009, 0.1984, 0.2023])\n"
     ]
    }
   ],
   "source": [
    "CIFAR100_data = CIFAR100(\n",
    "            root=r\"/dataset/CIFAR100\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "        )\n",
    "\n",
    "loader = DataLoader(\n",
    "    CIFAR100_data,\n",
    "    batch_size=10,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "nimages = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for batch, _ in loader:\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    std += batch.std(2).sum(0)\n",
    "\n",
    "# Final step\n",
    "mean /= nimages\n",
    "std /= nimages\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "tensor([0.4808, 0.4808, 0.4808])\n",
      "tensor([0.1963, 0.1963, 0.1963])\n"
     ]
    }
   ],
   "source": [
    "cifar10 =CIFAR10(\n",
    "            root=r\"/dataset/CHIFAR10/\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                    [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Grayscale(3)\n",
    "                    ]\n",
    "                ))\n",
    "\n",
    "\n",
    "loader = DataLoader(\n",
    "    cifar10,\n",
    "    batch_size=10,\n",
    "    num_workers=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "nimages = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for batch, _ in loader:\n",
    "    # Rearrange batch to be the shape of [B, C, W * H]\n",
    "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
    "    # Update total number of images\n",
    "    nimages += batch.size(0)\n",
    "    # Compute mean and std here\n",
    "    mean += batch.mean(2).sum(0) \n",
    "    std += batch.std(2).sum(0)\n",
    "\n",
    "# Final step\n",
    "mean /= nimages\n",
    "std /= nimages\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_active_learning.data.datamanager import Data_manager\n",
    "from robust_active_learning.data.datahandler_for_array import create_dataloader\n",
    "from robust_active_learning.data.deprecated.datahandler_for_array import create_dataloader as create_dataloader_old\n",
    "from robust_active_learning.data.deprecated.datamanager import get_datamanager as get_datamanager_old\n",
    "from robust_active_learning.data.deprecated.sampler import DDU_sampler as DDU_sampler_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torchvision.datasets.cifar import CIFAR100\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.datasets import MNIST, FashionMNIST, SVHN, CIFAR10\n",
    "from torch.utils.data import Subset, ConcatDataset\n",
    "import copy\n",
    "\n",
    "def data_loader(datasets_list: list, grayscale=False) -> dict:\n",
    "    \"\"\"\n",
    "    This function takes in a list of datasets to be used in the experiments\n",
    "    \"\"\"\n",
    "    print(f\"INFO ------ List of datasets being loaded are {datasets_list}\")\n",
    "\n",
    "    datasets_dict = {}\n",
    "    if \"CIFAR10\" in datasets_list:\n",
    "        if not grayscale:\n",
    "            cifar_train_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                ]\n",
    "            )\n",
    "            cifar_test_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            cifar_train_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Grayscale(3),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                ]\n",
    "            )\n",
    "            cifar_test_transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Grayscale(3),\n",
    "                ]\n",
    "            )\n",
    "        datasets_dict[\"CIFAR10_train\"] = CIFAR10(\n",
    "            root=r\"/dataset/CHIFAR10/\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=cifar_train_transform,\n",
    "        )\n",
    "        datasets_dict[\"CIFAR10_test\"] = CIFAR10(\n",
    "            root=r\"/dataset/CHIFAR10/\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=cifar_test_transform,\n",
    "        )\n",
    "\n",
    "        print(\"INFO ----- Dataset Loaded : CIFAR10\")\n",
    "        datasets_list.remove(\"CIFAR10\")\n",
    "\n",
    "    if \"MNIST\" in datasets_list:\n",
    "        mnist_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Pad(2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(tmp_func),\n",
    "                transforms.RandomCrop(32, 4),\n",
    "            ]\n",
    "        )\n",
    "        datasets_dict[\"MNIST_train\"] = MNIST(\n",
    "            root=r\"/dataset/MNIST\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=mnist_transforms,\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"MNIST_test\"] = MNIST(\n",
    "            root=r\"/dataset/MNIST\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=mnist_transforms,\n",
    "        )\n",
    "\n",
    "        print(\"INFO ----- Dataset Loaded : MNIST\")\n",
    "        datasets_list.remove(\"MNIST\")\n",
    "\n",
    "    if \"FashionMNIST\" in datasets_list:\n",
    "        fmnist_transforms = transforms.Compose(\n",
    "            [\n",
    "                transforms.Pad(2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Lambda(tmp_func),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomCrop(32, 4),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"FashionMNIST_train\"] = FashionMNIST(\n",
    "            root=\"/dataset/FashionMNIST\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=fmnist_transforms,\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"FashionMNIST_test\"] = FashionMNIST(\n",
    "            root=\"/dataset/FashionMNIST\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=fmnist_transforms,\n",
    "        )\n",
    "\n",
    "        print(\"INFO ----- Dataset Loaded : FashionMNIST\")\n",
    "        datasets_list.remove(\"FashionMNIST\")\n",
    "\n",
    "    if \"SVHN\" in datasets_list:\n",
    "        SVHN_transforms = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Resize(32), transforms.RandomCrop(32, 4)]\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"SVHN_train\"] = SVHN(\n",
    "            root=r\"/dataset/SVHN\",\n",
    "            split=\"train\",\n",
    "            download=True,\n",
    "            transform=SVHN_transforms,\n",
    "        )\n",
    "        datasets_dict[\"SVHN_train\"].targets = datasets_dict[\"SVHN_train\"].labels\n",
    "        datasets_dict[\"SVHN_test\"] = SVHN(\n",
    "            root=r\"/dataset/SVHN\",\n",
    "            split=\"test\",\n",
    "            download=True,\n",
    "            transform=SVHN_transforms,\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"SVHN_test\"].targets = datasets_dict[\"SVHN_test\"].labels\n",
    "        print(\"INFO ----- Dataset Loaded : SVHN\")\n",
    "        datasets_list.remove(\"SVHN\")\n",
    "\n",
    "    if \"CIFAR100\" in datasets_list:\n",
    "        datasets_dict[\"CIFAR100_train\"] = CIFAR100(\n",
    "            root=r\"/dataset/CIFAR100\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"CIFAR100_test\"] = CIFAR100(\n",
    "            root=r\"/dataset/CIFAR100\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "        )\n",
    "\n",
    "        print(\"INFO ----- Dataset Loaded : CIFAR100\")\n",
    "        datasets_list.remove(\"CIFAR100\")\n",
    "\n",
    "    if \"CIFAR10_ood\" in datasets_list:\n",
    "\n",
    "        cifar_train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.RandomCrop(32, 4),\n",
    "            ]\n",
    "        )\n",
    "        cifar_test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"CIFAR10_ood_train\"] = CIFAR10(\n",
    "            root=r\"/dataset/CHIFAR10/\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=cifar_train_transform,\n",
    "        )\n",
    "        datasets_dict[\"CIFAR10_ood_test\"] = CIFAR10(\n",
    "            root=r\"/dataset/CHIFAR10/\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=cifar_test_transform,\n",
    "        )\n",
    "\n",
    "        print(\"INFO ----- Dataset Loaded : CIFAR10_ood\")\n",
    "        datasets_list.remove(\"CIFAR10_ood\")\n",
    "\n",
    "    if \"CIFAR100_ood\" in datasets_list:\n",
    "        datasets_dict[\"CIFAR100_ood_train\"] = CIFAR100(\n",
    "            root=r\"/dataset/CIFAR100\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        datasets_dict[\"CIFAR100_ood_test\"] = CIFAR100(\n",
    "            root=r\"/dataset/CIFAR100\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms.ToTensor(),\n",
    "        )\n",
    "\n",
    "        print(\"INFO ----- Dataset Loaded : CIFAR100_ood\")\n",
    "        datasets_list.remove(\"CIFAR100_ood\")\n",
    "\n",
    "    assert (\n",
    "        len(datasets_list) == 0\n",
    "    ), f\"Not all datasets have been loaded, datasets left : {datasets_list}\"\n",
    "\n",
    "    return datasets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ------ List of datasets being loaded are ['CIFAR100', 'CIFAR100_ood']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO ----- Dataset Loaded : CIFAR100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO ----- Dataset Loaded : CIFAR100_ood\n"
     ]
    }
   ],
   "source": [
    "list_of_datasets = [\"CIFAR100\",\"CIFAR100_ood\"]\n",
    "datasets_dict = data_loader(list_of_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "iD_datasets = [\"CIFAR100\"]\n",
    "subclass= {\n",
    "          \"do_subclass\": True,\n",
    "          \"iD_classes\": [0, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, \n",
    "                            68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99],\n",
    "          \"OoD_classes\": [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n",
    "        }\n",
    "\n",
    "dataset = \"CIFAR100\"\n",
    "cls = set(subclass[\"iD_classes\"])\n",
    "idx_train = [\n",
    "    i\n",
    "    for i, val in enumerate(\n",
    "        datasets_dict[dataset + \"_train\"].targets\n",
    "    )\n",
    "    if val in cls\n",
    "]\n",
    "idx_test = [\n",
    "    i\n",
    "    for i, val in enumerate(\n",
    "        datasets_dict[dataset + \"_test\"].targets\n",
    "    )\n",
    "    if val in cls\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_rand = [\n",
    "    i\n",
    "    for i, val in enumerate(\n",
    "        rand_list\n",
    "    )\n",
    "    if val in cls\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "test = np.take(\n",
    "    idx_train, datasets_dict[dataset + \"_train\"].targets, axis=0\n",
    ")\n",
    "print(len(test))\n",
    "print(len(np.unique(datasets_dict[dataset + \"_train\"].targets)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict[dataset + \"_train\"].data = np.take(\n",
    "    datasets_dict[dataset + \"_train\"].data, idx_train,  axis=0\n",
    ")\n",
    "datasets_dict[dataset + \"_train\"].targets = np.take(\n",
    "    datasets_dict[dataset + \"_train\"].targets, idx_train,  axis=0\n",
    ")\n",
    "\n",
    "datasets_dict[dataset + \"_test\"].data = np.take(\n",
    "    datasets_dict[dataset + \"_test\"].data, idx_test,  axis=0\n",
    ")\n",
    "datasets_dict[dataset + \"_test\"].targets = np.take(\n",
    "    datasets_dict[dataset + \"_test\"].targets, idx_test,  axis=0\n",
    ").tolist()\n",
    "\n",
    "new_labels = [\n",
    "    subclass[\"iD_classes\"].index(i) for i in subclass[\"iD_classes\"]\n",
    "]\n",
    "datasets_dict[dataset + \"_train\"].targets = [\n",
    "    new_labels[subclass[\"iD_classes\"].index(i)]\n",
    "    for i in datasets_dict[dataset + \"_train\"].targets\n",
    "]\n",
    "\n",
    "datasets_dict[dataset + \"_test\"].targets = [\n",
    "    new_labels[subclass[\"iD_classes\"].index(i)]\n",
    "    for i in datasets_dict[dataset + \"_test\"].targets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79]\n"
     ]
    }
   ],
   "source": [
    "print(len(datasets_dict[dataset + \"_train\"].targets))\n",
    "print((np.unique(datasets_dict[dataset + \"_train\"].targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8316/1578565569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatasets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'datasets_dict' is not defined"
     ]
    }
   ],
   "source": [
    "datasets_dict[dataset + \"_test\"].targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ------ List of datasets being loaded are ['CIFAR100', 'CIFAR100_ood']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO ----- Dataset Loaded : CIFAR100\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO ----- Dataset Loaded : CIFAR100_ood\n",
      "40000\n",
      "80\n",
      "INFO ----- Total iD samples for training  40000\n",
      "INFO ----- Total iD samples for testing  8000\n",
      "INFO ----- Total OoD samples for training 10000\n",
      "Creating New Dataset\n",
      "Running Experiment without Pool\n",
      "Status_manager intialised\n",
      "INFO ------ Validation source not specified in config, experiment would run without validation set\n"
     ]
    }
   ],
   "source": [
    "datamanger = Data_manager(\n",
    "            iD_datasets=[\"CIFAR100\"],\n",
    "        OoD_datasets=[\"CIFAR100_ood\"],\n",
    "        labelled_size=500,\n",
    "        pool_size=5000,\n",
    "        OoD_ratio=0.0,\n",
    "        test_iD_size=None,\n",
    "        grayscale=False,\n",
    "        subclass= {\n",
    "          \"do_subclass\": True,\n",
    "          \"iD_classes\": [0, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 31, 32, 33, 34, 36, 37, 38, 39, 41, 42, 43, 44, 46, 47, 48, 49, 51, 52, 53, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, \n",
    "                            68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 98, 99],\n",
    "          \"OoD_classes\": [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]\n",
    "        }\n",
    ")\n",
    "datamanger.create_merged_data()\n",
    "data_loader_tupel = create_dataloader(datamanger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader ,_,_ = data_loader_tupel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,targets = sample_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31, 39, 11, 23, 71, 41, 46, 41, 28, 72,  2, 78, 12,  4, 54, 23, 19,  4,\n",
       "        58, 52, 26, 12, 65, 70, 79, 35, 66, 18, 73, 59, 74, 70, 74, 57, 31, 13,\n",
       "        40,  1, 44, 67, 19, 66, 55, 16, 78, 69, 21,  7, 60,  1, 31, 15, 28, 28,\n",
       "        15, 26, 71, 61, 72, 64, 14, 27,  9, 21, 38, 51, 23, 44, 37, 60, 35, 18,\n",
       "        10,  6,  7, 36, 43, 49, 46, 68, 53, 50, 32, 76, 10, 64, 23, 50, 28,  0,\n",
       "        37, 57, 63, 55, 52, 45, 52, 32,  6, 36, 55, 20, 30, 36, 35, 77, 34, 62,\n",
       "        35, 70, 12, 27, 73,  9, 20,  6, 33, 70,  9, 69, 42, 13, 17, 77,  4, 31,\n",
       "        11, 58])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img.transpose(), interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nk\\Python-proj\\SRP\\SRPHildesheim2021\\.venv\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from robust_active_learning.experiment_ddu import experiment_ddu\n",
    "\n",
    "basic_settings = {\n",
    "\"oracle_stepsize\": 50,\n",
    "\"oracle_steps\": 3,\n",
    "\"iD\": \"CIFAR10\",\n",
    "\"OoD\": [\"FashionMNIST\", \"MNIST\"],\n",
    "\"grayscale\": True,\n",
    "\"subclass\": {\n",
    "    \"do_subclass\": False,\n",
    "    \"iD_classes\": [],\n",
    "    \"OoD_classes\": []\n",
    "},\n",
    "\"labelled_size\": 2000,\n",
    "\"pool_size\": 15000,\n",
    "\"OOD_ratio\": 0.15,\n",
    "\"epochs\": 100,\n",
    "\"batch_size\": 64,\n",
    "\"weight_decay\": 1e-4,\n",
    "\"metric\": \"accuracy\",\n",
    "\"lr\": 0.1,\n",
    "\"nesterov\": False,\n",
    "\"momentum\": 0.9,\n",
    "\"lr_sheduler\": True,\n",
    "\"num_classes\": 10,\n",
    "\"validation_split\": 0.1,\n",
    "\"validation_source\": \"test\",\n",
    "\"criterion\": \"crossentropy\",\n",
    "\"verbose\": 1\n",
    "}\n",
    "exp_settings = {\n",
    "    \"exp_type\": \"ddu\",\n",
    "    \"exp_name\": \"ddu-cifar-015\",\n",
    "    \"plots\": False,\n",
    "    \"model\": \"DDU\",\n",
    "    \"oracle\": \"ddu-sampler\",\n",
    "    \"spectral_normalization\": True,\n",
    "    \"temp\": 1.0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories created\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "def create_log_dirs(log_path):\n",
    "    if os.path.exists(log_path) == False:\n",
    "        os.makedirs(log_path)\n",
    "\n",
    "    status_manager_path = os.path.join(log_path, \"status_manager_dir\")\n",
    "    writer_path = os.path.join(log_path, \"writer_dir\")\n",
    "    log_dir_path = os.path.join(log_path, \"log_dir\")\n",
    "\n",
    "    if os.path.exists(status_manager_path) == False:\n",
    "        os.mkdir(status_manager_path)\n",
    "    if os.path.exists(writer_path) == False:\n",
    "        os.mkdir(writer_path)\n",
    "    if os.path.exists(log_dir_path) == False:\n",
    "        os.mkdir(log_dir_path)\n",
    "\n",
    "    print(\"Directories created\")\n",
    "\n",
    "log_path = os.path.join(\"./logs\")\n",
    "\n",
    "log_path = os.path.join(log_path, time.strftime(\"%m-%d-%H-%M\", time.localtime()))\n",
    "create_log_dirs(log_path)\n",
    "\n",
    "writer = SummaryWriter(os.path.join(log_path, \"writer_dir\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ddu_old=experiment_ddu(basic_settings,exp_settings, log_path, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ------ List of datasets being loaded are ['CIFAR10', 'FashionMNIST', 'MNIST']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "INFO ----- Dataset Loaded : CIFAR10\n",
      "INFO ----- Dataset Loaded : MNIST\n",
      "INFO ----- Dataset Loaded : FashionMNIST\n",
      "INFO ----- Total iD samples for training  50000\n",
      "INFO ----- Total iD samples for testing  10000\n",
      "INFO ----- Total OoD samples for training 120000\n",
      "initialised datamanager\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Data_manager' object has no attribute 'status_manager'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9312/83093789.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexp_ddu_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct_datamanager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp_ddu_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatamanager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Data_manager' object has no attribute 'status_manager'"
     ]
    }
   ],
   "source": [
    "exp_ddu_old.construct_datamanager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating New Dataset\n",
      "Status_manager intialised\n"
     ]
    }
   ],
   "source": [
    "exp_ddu_old.datamanager.create_merged_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inds</th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28744.068529</td>\n",
       "      <td>8.625000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16702.116379</td>\n",
       "      <td>2.781156</td>\n",
       "      <td>0.866051</td>\n",
       "      <td>0.322199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14420.250000</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28483.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42823.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>59997.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               inds        target        source        status\n",
       "count  17000.000000  17000.000000  17000.000000  17000.000000\n",
       "mean   28744.068529      8.625000     -0.500000      0.117647\n",
       "std    16702.116379      2.781156      0.866051      0.322199\n",
       "min        2.000000      0.000000     -1.000000      0.000000\n",
       "25%    14420.250000      9.750000     -1.000000      0.000000\n",
       "50%    28483.000000     10.000000     -1.000000      0.000000\n",
       "75%    42823.000000     10.000000     -0.500000      0.000000\n",
       "max    59997.000000     10.000000      1.000000      1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ddu_old.datamanager.status_manager.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ------ List of datasets being loaded are ['CIFAR10', 'FashionMNIST', 'MNIST']\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO ----- Dataset Loaded : CIFAR10\n",
      "INFO ----- Dataset Loaded : MNIST\n",
      "INFO ----- Dataset Loaded : FashionMNIST\n",
      "INFO ----- Total iD samples for training  50000\n",
      "INFO ----- Total iD samples for testing  10000\n",
      "INFO ----- Total OoD samples for training 120000\n",
      "initialised datamanager\n",
      "loaded statusmanager from file\n",
      "Using Training data to create validation dataset, size : 200\n",
      "\n",
      "Training with device : cuda:0\n",
      "Number of Training Samples :  1800\n",
      "Number of Validation Samples :  200\n",
      "Number of Epochs :  100\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─BatchNorm2d: 1-1                            32\n",
      "├─Conv2d: 1-2                                 432\n",
      "├─Sequential: 1-3                             --\n",
      "|    └─BasicBlock: 2-1                        --\n",
      "|    |    └─Conv2d: 3-1                       2,304\n",
      "|    |    └─BatchNorm2d: 3-2                  32\n",
      "|    |    └─Conv2d: 3-3                       2,304\n",
      "|    |    └─BatchNorm2d: 3-4                  32\n",
      "|    |    └─Sequential: 3-5                   --\n",
      "|    └─BasicBlock: 2-2                        --\n",
      "|    |    └─Conv2d: 3-6                       2,304\n",
      "|    |    └─BatchNorm2d: 3-7                  32\n",
      "|    |    └─Conv2d: 3-8                       2,304\n",
      "|    |    └─BatchNorm2d: 3-9                  32\n",
      "|    |    └─Sequential: 3-10                  --\n",
      "|    └─BasicBlock: 2-3                        --\n",
      "|    |    └─Conv2d: 3-11                      2,304\n",
      "|    |    └─BatchNorm2d: 3-12                 32\n",
      "|    |    └─Conv2d: 3-13                      2,304\n",
      "|    |    └─BatchNorm2d: 3-14                 32\n",
      "|    |    └─Sequential: 3-15                  --\n",
      "├─Sequential: 1-4                             --\n",
      "|    └─BasicBlock: 2-4                        --\n",
      "|    |    └─Conv2d: 3-16                      4,608\n",
      "|    |    └─BatchNorm2d: 3-17                 64\n",
      "|    |    └─Conv2d: 3-18                      9,216\n",
      "|    |    └─BatchNorm2d: 3-19                 64\n",
      "|    |    └─Sequential: 3-20                  --\n",
      "|    └─BasicBlock: 2-5                        --\n",
      "|    |    └─Conv2d: 3-21                      9,216\n",
      "|    |    └─BatchNorm2d: 3-22                 64\n",
      "|    |    └─Conv2d: 3-23                      9,216\n",
      "|    |    └─BatchNorm2d: 3-24                 64\n",
      "|    |    └─Sequential: 3-25                  --\n",
      "|    └─BasicBlock: 2-6                        --\n",
      "|    |    └─Conv2d: 3-26                      9,216\n",
      "|    |    └─BatchNorm2d: 3-27                 64\n",
      "|    |    └─Conv2d: 3-28                      9,216\n",
      "|    |    └─BatchNorm2d: 3-29                 64\n",
      "|    |    └─Sequential: 3-30                  --\n",
      "├─Sequential: 1-5                             --\n",
      "|    └─BasicBlock: 2-7                        --\n",
      "|    |    └─Conv2d: 3-31                      18,432\n",
      "|    |    └─BatchNorm2d: 3-32                 128\n",
      "|    |    └─Conv2d: 3-33                      36,864\n",
      "|    |    └─BatchNorm2d: 3-34                 128\n",
      "|    |    └─Sequential: 3-35                  --\n",
      "|    └─BasicBlock: 2-8                        --\n",
      "|    |    └─Conv2d: 3-36                      36,864\n",
      "|    |    └─BatchNorm2d: 3-37                 128\n",
      "|    |    └─Conv2d: 3-38                      36,864\n",
      "|    |    └─BatchNorm2d: 3-39                 128\n",
      "|    |    └─Sequential: 3-40                  --\n",
      "|    └─BasicBlock: 2-9                        --\n",
      "|    |    └─Conv2d: 3-41                      36,864\n",
      "|    |    └─BatchNorm2d: 3-42                 128\n",
      "|    |    └─Conv2d: 3-43                      36,864\n",
      "|    |    └─BatchNorm2d: 3-44                 128\n",
      "|    |    └─Sequential: 3-45                  --\n",
      "├─Linear: 1-6                                 2,570\n",
      "├─Softmax: 1-7                                --\n",
      "======================================================================\n",
      "Total params: 271,642\n",
      "Trainable params: 271,642\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "INFO ------ Early Stopping Patience not specified using 10\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:08<13:31,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.634883).  Saving model ...\n",
      "Val_loss: 2.6349 Val_acc : 18.50\n",
      "Train_loss: 2.0720 Train_acc : 20.83\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:16<13:29,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.634883 --> 1.912824).  Saving model ...\n",
      "Val_loss: 1.9128 Val_acc : 30.50\n",
      "Train_loss: 1.8522 Train_acc : 29.17\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:24<13:07,  8.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.912824 --> 1.839704).  Saving model ...\n",
      "Val_loss: 1.8397 Val_acc : 34.00\n",
      "Train_loss: 1.7516 Train_acc : 33.83\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:32<12:54,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.839704 --> 1.745342).  Saving model ...\n",
      "Val_loss: 1.7453 Val_acc : 37.00\n",
      "Train_loss: 1.6788 Train_acc : 36.61\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:41<13:19,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.9560 Val_acc : 28.00\n",
      "Train_loss: 1.6484 Train_acc : 39.06\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:49<13:11,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "Val_loss: 1.7810 Val_acc : 35.00\n",
      "Train_loss: 1.6705 Train_acc : 37.11\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:58<13:05,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "Val_loss: 1.8338 Val_acc : 35.00\n",
      "Train_loss: 1.6093 Train_acc : 39.06\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:07<13:03,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "Val_loss: 1.8451 Val_acc : 34.50\n",
      "Train_loss: 1.5849 Train_acc : 42.22\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:15<13:01,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.745342 --> 1.588664).  Saving model ...\n",
      "Val_loss: 1.5887 Val_acc : 42.50\n",
      "Train_loss: 1.4872 Train_acc : 44.33\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:24<12:49,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.6000 Val_acc : 41.50\n",
      "Train_loss: 1.4516 Train_acc : 46.33\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:32<12:43,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "Val_loss: 2.4060 Val_acc : 31.00\n",
      "Train_loss: 1.4119 Train_acc : 47.89\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [01:42<12:58,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "Val_loss: 1.8936 Val_acc : 32.00\n",
      "Train_loss: 1.3931 Train_acc : 47.44\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:52<13:13,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "Val_loss: 1.6707 Val_acc : 42.50\n",
      "Train_loss: 1.3488 Train_acc : 50.17\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [02:01<13:08,  9.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.588664 --> 1.516386).  Saving model ...\n",
      "Val_loss: 1.5164 Val_acc : 45.50\n",
      "Train_loss: 1.3144 Train_acc : 51.33\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [02:10<12:56,  9.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.7773 Val_acc : 43.00\n",
      "Train_loss: 1.3186 Train_acc : 52.00\n",
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [02:19<12:34,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.516386 --> 1.492600).  Saving model ...\n",
      "Val_loss: 1.4926 Val_acc : 46.50\n",
      "Train_loss: 1.2712 Train_acc : 53.17\n",
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [02:27<12:15,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.4949 Val_acc : 55.50\n",
      "Train_loss: 1.2182 Train_acc : 55.50\n",
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:36<12:03,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "Val_loss: 1.4960 Val_acc : 48.50\n",
      "Train_loss: 1.1964 Train_acc : 57.00\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [02:45<11:50,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "Val_loss: 1.9330 Val_acc : 39.50\n",
      "Train_loss: 1.2084 Train_acc : 56.44\n",
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [02:53<11:37,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.492600 --> 1.302654).  Saving model ...\n",
      "Val_loss: 1.3027 Val_acc : 51.00\n",
      "Train_loss: 1.1219 Train_acc : 60.39\n",
      "\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [03:02<11:24,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.5388 Val_acc : 52.00\n",
      "Train_loss: 1.1074 Train_acc : 59.39\n",
      "\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [03:11<11:23,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "Val_loss: 1.4703 Val_acc : 50.50\n",
      "Train_loss: 1.0555 Train_acc : 60.28\n",
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [03:19<11:10,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "Val_loss: 2.0015 Val_acc : 44.50\n",
      "Train_loss: 1.0171 Train_acc : 63.39\n",
      "\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [03:28<10:59,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "Val_loss: 1.4951 Val_acc : 51.50\n",
      "Train_loss: 1.0286 Train_acc : 63.17\n",
      "\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [03:37<10:59,  8.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n",
      "Val_loss: 1.4088 Val_acc : 48.00\n",
      "Train_loss: 0.9896 Train_acc : 65.00\n",
      "\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [03:46<10:48,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Val_loss: 1.7212 Val_acc : 43.50\n",
      "Train_loss: 0.9644 Train_acc : 65.00\n",
      "\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:54<10:32,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 10\n",
      "Val_loss: 1.3215 Val_acc : 54.50\n",
      "Train_loss: 0.8309 Train_acc : 70.28\n",
      "\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [04:02<10:12,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.302654 --> 1.116416).  Saving model ...\n",
      "Val_loss: 1.1164 Val_acc : 58.00\n",
      "Train_loss: 0.7921 Train_acc : 72.89\n",
      "\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [04:11<10:17,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.1768 Val_acc : 57.50\n",
      "Train_loss: 0.7449 Train_acc : 74.22\n",
      "\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [04:20<10:10,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "Val_loss: 1.2140 Val_acc : 56.50\n",
      "Train_loss: 0.7249 Train_acc : 75.67\n",
      "\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [04:29<10:01,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "Val_loss: 1.1417 Val_acc : 58.00\n",
      "Train_loss: 0.7198 Train_acc : 75.44\n",
      "\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [04:38<09:54,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "Val_loss: 1.1279 Val_acc : 53.50\n",
      "Train_loss: 0.6741 Train_acc : 76.83\n",
      "\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [04:46<09:40,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n",
      "Val_loss: 1.2084 Val_acc : 55.50\n",
      "Train_loss: 0.6945 Train_acc : 76.67\n",
      "\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [04:55<09:41,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Val_loss: 1.1872 Val_acc : 53.50\n",
      "Train_loss: 0.6937 Train_acc : 77.11\n",
      "\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [05:04<09:32,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 10\n",
      "Val_loss: 1.2241 Val_acc : 58.00\n",
      "Train_loss: 0.6673 Train_acc : 76.83\n",
      "\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [05:13<09:24,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 8 out of 10\n",
      "Val_loss: 1.2041 Val_acc : 56.00\n",
      "Train_loss: 0.6327 Train_acc : 77.33\n",
      "\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [05:22<09:18,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 9 out of 10\n",
      "Val_loss: 1.2130 Val_acc : 54.00\n",
      "Train_loss: 0.6323 Train_acc : 77.67\n",
      "\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [05:31<09:23,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 10 out of 10\n",
      "Val_loss: 1.1474 Val_acc : 56.50\n",
      "Early stopping epoch 38 , avg train_loss 0.6743426949813448, avg val loss 1.1473781764507294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 29/29 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting gmm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished pool prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:08<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished gmm evaluation\n",
      "    inds  target  source  status   dataset_name\n",
      "0  29140       0       1       1  CIFAR10_train\n",
      "1  33006       5       1       1  CIFAR10_train\n",
      "2  16239       8       1       1  CIFAR10_train\n",
      "3  45903       5       1       1  CIFAR10_train\n",
      "4  11420       2       1       1  CIFAR10_train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 1.1672373972121317, 'train_loss': 0.6743426949813448, 'test_accuracy': 59.199999999999996, 'train_accuracy': 0.7811111111111111, 'f1': 0.5920706758664107}\n",
      "Sampling result {'Base_examples_labelled': 1, 'OOD_examples_labelled': 49} 1\n",
      "Using Training data to create validation dataset, size : 200\n",
      "\n",
      "Training with device : cuda:0\n",
      "Number of Training Samples :  1801\n",
      "Number of Validation Samples :  200\n",
      "Number of Epochs :  100\n",
      "======================================================================\n",
      "Layer (type:depth-idx)                        Param #\n",
      "======================================================================\n",
      "├─BatchNorm2d: 1-1                            32\n",
      "├─Conv2d: 1-2                                 432\n",
      "├─Sequential: 1-3                             --\n",
      "|    └─BasicBlock: 2-1                        --\n",
      "|    |    └─Conv2d: 3-1                       2,304\n",
      "|    |    └─BatchNorm2d: 3-2                  32\n",
      "|    |    └─Conv2d: 3-3                       2,304\n",
      "|    |    └─BatchNorm2d: 3-4                  32\n",
      "|    |    └─Sequential: 3-5                   --\n",
      "|    └─BasicBlock: 2-2                        --\n",
      "|    |    └─Conv2d: 3-6                       2,304\n",
      "|    |    └─BatchNorm2d: 3-7                  32\n",
      "|    |    └─Conv2d: 3-8                       2,304\n",
      "|    |    └─BatchNorm2d: 3-9                  32\n",
      "|    |    └─Sequential: 3-10                  --\n",
      "|    └─BasicBlock: 2-3                        --\n",
      "|    |    └─Conv2d: 3-11                      2,304\n",
      "|    |    └─BatchNorm2d: 3-12                 32\n",
      "|    |    └─Conv2d: 3-13                      2,304\n",
      "|    |    └─BatchNorm2d: 3-14                 32\n",
      "|    |    └─Sequential: 3-15                  --\n",
      "├─Sequential: 1-4                             --\n",
      "|    └─BasicBlock: 2-4                        --\n",
      "|    |    └─Conv2d: 3-16                      4,608\n",
      "|    |    └─BatchNorm2d: 3-17                 64\n",
      "|    |    └─Conv2d: 3-18                      9,216\n",
      "|    |    └─BatchNorm2d: 3-19                 64\n",
      "|    |    └─Sequential: 3-20                  --\n",
      "|    └─BasicBlock: 2-5                        --\n",
      "|    |    └─Conv2d: 3-21                      9,216\n",
      "|    |    └─BatchNorm2d: 3-22                 64\n",
      "|    |    └─Conv2d: 3-23                      9,216\n",
      "|    |    └─BatchNorm2d: 3-24                 64\n",
      "|    |    └─Sequential: 3-25                  --\n",
      "|    └─BasicBlock: 2-6                        --\n",
      "|    |    └─Conv2d: 3-26                      9,216\n",
      "|    |    └─BatchNorm2d: 3-27                 64\n",
      "|    |    └─Conv2d: 3-28                      9,216\n",
      "|    |    └─BatchNorm2d: 3-29                 64\n",
      "|    |    └─Sequential: 3-30                  --\n",
      "├─Sequential: 1-5                             --\n",
      "|    └─BasicBlock: 2-7                        --\n",
      "|    |    └─Conv2d: 3-31                      18,432\n",
      "|    |    └─BatchNorm2d: 3-32                 128\n",
      "|    |    └─Conv2d: 3-33                      36,864\n",
      "|    |    └─BatchNorm2d: 3-34                 128\n",
      "|    |    └─Sequential: 3-35                  --\n",
      "|    └─BasicBlock: 2-8                        --\n",
      "|    |    └─Conv2d: 3-36                      36,864\n",
      "|    |    └─BatchNorm2d: 3-37                 128\n",
      "|    |    └─Conv2d: 3-38                      36,864\n",
      "|    |    └─BatchNorm2d: 3-39                 128\n",
      "|    |    └─Sequential: 3-40                  --\n",
      "|    └─BasicBlock: 2-9                        --\n",
      "|    |    └─Conv2d: 3-41                      36,864\n",
      "|    |    └─BatchNorm2d: 3-42                 128\n",
      "|    |    └─Conv2d: 3-43                      36,864\n",
      "|    |    └─BatchNorm2d: 3-44                 128\n",
      "|    |    └─Sequential: 3-45                  --\n",
      "├─Linear: 1-6                                 2,570\n",
      "├─Softmax: 1-7                                --\n",
      "======================================================================\n",
      "Total params: 271,642\n",
      "Trainable params: 271,642\n",
      "Non-trainable params: 0\n",
      "======================================================================\n",
      "INFO ------ Early Stopping Patience not specified using 10\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:09<14:57,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.183149).  Saving model ...\n",
      "Val_loss: 2.1831 Val_acc : 18.50\n",
      "Train_loss: 2.0792 Train_acc : 22.32\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:18<14:46,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.183149 --> 1.990014).  Saving model ...\n",
      "Val_loss: 1.9900 Val_acc : 35.00\n",
      "Train_loss: 1.7936 Train_acc : 32.93\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:18<15:30,  9.49s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10916/1662216568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexp_ddu_old\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_ddu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_settings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexp_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp_ddu_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPFixedSoftmax\\robust_active_learning\\experiment_ddu.py\u001b[0m in \u001b[0;36mperform_experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m             self.train(\n\u001b[0m\u001b[0;32m    511\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPFixedSoftmax\\robust_active_learning\\experiment_ddu.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_loader, val_loader, optimizer, criterion, device, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPHildesheim2021\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPHildesheim2021\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_worker_number_rationality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPHildesheim2021\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    119\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp_ddu_old=experiment_ddu(basic_settings,exp_settings, log_path, writer)\n",
    "#exp_ddu_old.perform_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds=[0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  source  status\n",
       "0     1.0     1.0     1.0\n",
       "1     3.0     1.0     1.0\n",
       "2     4.0     1.0     1.0\n",
       "3     2.0     1.0     1.0\n",
       "4     5.0     1.0     1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ddu_old.datamanager.status_manager[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>source</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19647.000000</td>\n",
       "      <td>19647.000000</td>\n",
       "      <td>19647.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.758996</td>\n",
       "      <td>0.730544</td>\n",
       "      <td>0.106887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.265803</td>\n",
       "      <td>0.682883</td>\n",
       "      <td>0.317107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target        source        status\n",
       "count  19647.000000  19647.000000  19647.000000\n",
       "mean       3.758996      0.730544      0.106887\n",
       "std        3.265803      0.682883      0.317107\n",
       "min       -1.000000     -1.000000      0.000000\n",
       "25%        1.000000      1.000000      0.000000\n",
       "50%        4.000000      1.000000      0.000000\n",
       "75%        7.000000      1.000000      0.000000\n",
       "max        9.000000      1.000000      2.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ddu_old.datamanager.status_manager.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ddu_old.datamanager.status_manager[\"status\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_ddu_old.datamanager.status_manager.iloc[:, -1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (140000, 3, 32, 32) (140000,)\n",
      "Base-data shape:  (50000, 3, 32, 32)\n",
      "OOD_data shape:  (140000, 3, 32, 32)\n",
      "Creating New Dataset\n",
      "Experiment_Setup saved\n",
      "Status_manager intialised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Testing data to create validation dataset, size : 1000\n",
      "\n",
      "Training with device : cuda:0\n",
      "Number of Training Samples :  2000\n",
      "Number of Validation Samples :  1000\n",
      "Number of Epochs :  100\n",
      "INFO ------ Early Stopping Patience not specified using 10\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:07<11:51,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 2.294787).  Saving model ...\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:11<08:54,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (2.294787 --> 1.742297).  Saving model ...\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:15<08:05,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.742297 --> 1.659899).  Saving model ...\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:20<07:41,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.659899 --> 1.592670).  Saving model ...\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:24<07:27,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:29<07:07,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.592670 --> 1.485416).  Saving model ...\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:33<06:56,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:37<06:42,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:41<06:30,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.485416 --> 1.396738).  Saving model ...\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:46<06:28,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "Val_loss: 1.7314 Val_acc : 37.50\n",
      "Train_loss: 1.2852 Train_acc : 51.85\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:50<06:29,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:55<06:28,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:59<06:32,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.396738 --> 1.351983).  Saving model ...\n",
      "\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:04<06:31,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:09<06:26,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.351983 --> 1.326206).  Saving model ...\n",
      "\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:13<06:13,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:17<06:03,  4.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:22<06:17,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:27<06:07,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:31<05:56,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n",
      "Val_loss: 1.3279 Val_acc : 53.90\n",
      "Train_loss: 0.9476 Train_acc : 65.45\n",
      "\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:35<05:47,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.326206 --> 1.264182).  Saving model ...\n",
      "\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:39<05:43,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:44<05:34,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:48<05:25,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:53<05:35,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.264182 --> 1.152029).  Saving model ...\n",
      "\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:57<05:25,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [02:02<05:35,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [02:06<05:26,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [02:11<05:17,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:15<05:07,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n",
      "Val_loss: 1.2208 Val_acc : 58.10\n",
      "Train_loss: 0.6869 Train_acc : 76.25\n",
      "\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:19<05:04,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:24<05:06,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.152029 --> 1.096077).  Saving model ...\n",
      "\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:30<05:26,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.096077 --> 1.088877).  Saving model ...\n",
      "\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:34<05:14,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.088877 --> 1.079527).  Saving model ...\n",
      "\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:39<05:03,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:44<05:00,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 2 out of 10\n",
      "\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:48<04:52,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 3 out of 10\n",
      "\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:54<05:02,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 4 out of 10\n",
      "\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:58<04:48,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 5 out of 10\n",
      "\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [03:03<04:51,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 6 out of 10\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Val_loss: 1.1327 Val_acc : 63.40\n",
      "Train_loss: 0.4015 Train_acc : 86.80\n",
      "\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [03:08<04:44,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 7 out of 10\n",
      "\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [03:12<04:32,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 8 out of 10\n",
      "\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [03:16<04:20,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 9 out of 10\n",
      "\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [03:21<04:27,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping epoch 44 , avg train_loss 0.37865733075886965, avg val loss 1.1053590551018715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 32/32 [00:01<00:00, 16.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting gmm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/276 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished pool prediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 276/276 [00:04<00:00, 58.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished gmm evaluation\n",
      "   target  source  status\n",
      "0     1.0     1.0     1.0\n",
      "1     3.0     1.0     1.0\n",
      "2     4.0     1.0     1.0\n",
      "3     2.0     1.0     1.0\n",
      "4     5.0     1.0     1.0\n",
      "{'test_loss': 1.101796251662234, 'train_loss': 0.37865733075886965, 'test_accuracy': 65.76666666666667, 'train_accuracy': 0.882}\n",
      "Sampling result {'Base_examples_labelled': 50, 'OOD_examples_labelled': 0} 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Testing data to create validation dataset, size : 1000\n",
      "\n",
      "Training with device : cuda:0\n",
      "Number of Training Samples :  2050\n",
      "Number of Validation Samples :  1000\n",
      "Number of Epochs :  100\n",
      "INFO ------ Early Stopping Patience not specified using 10\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:06<09:57,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 1.855547).  Saving model ...\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:11<08:54,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:15<08:01,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.855547 --> 1.797516).  Saving model ...\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:20<07:52,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:24<07:28,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.797516 --> 1.767892).  Saving model ...\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:28<07:04,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:32<06:49,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.767892 --> 1.692452).  Saving model ...\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:36<06:30,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EarlyStopping counter: 1 out of 10\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:41<06:28,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.692452 --> 1.673795).  Saving model ...\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:45<06:27,  4.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (1.673795 --> 1.619933).  Saving model ...\n",
      "Val_loss: 1.6199 Val_acc : 42.20\n",
      "Train_loss: 1.5512 Train_acc : 43.71\n",
      "\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:47<07:05,  4.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20424/1790282674.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mexp_ddu_old\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexperiment_ddu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasic_settings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexp_settings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp_ddu_old\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperform_old_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPFixedSoftmax\\robust_active_learning\\experiment_ddu.py\u001b[0m in \u001b[0;36mperform_old_experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_optimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m             self.train(\n\u001b[0m\u001b[0;32m    619\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nk\\Python-proj\\SRP\\SRPFixedSoftmax\\robust_active_learning\\experiment_ddu.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_loader, val_loader, optimizer, criterion, device, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp_ddu_old=experiment_ddu(basic_settings,exp_settings, log_path, writer)\n",
    "exp_ddu_old.perform_old_experiment()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f81cb8167ba0d2c55e83ce55d6b90fb05a826bc02a259d06b2f2b1cb35f7d5d1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
